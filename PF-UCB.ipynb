{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from bandits import *\n",
    "from client import *\n",
    "from server import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96474458 0.09377086 0.85638765 0.55506951 0.20336919 0.32263036\n",
      "  0.06530855 0.35435463 0.30264855]\n",
      " [0.6808939  0.42081861 0.74369719 0.01659674 0.99540671 0.78499021\n",
      "  0.87432894 0.38923508 0.40590047]\n",
      " [0.99413358 0.44960078 0.93760862 0.53724053 0.35800793 0.55512393\n",
      "  0.3811849  0.09878918 0.95534792]\n",
      " [0.94559346 0.38608158 0.31329797 0.35656277 0.16833863 0.63256776\n",
      "  0.68181371 0.90621763 0.82996426]]\n",
      "M = 4, K = 9\n"
     ]
    }
   ],
   "source": [
    "T = int(1e6) # sum of rounds\n",
    "ENABLE_WARM_START = False # warm start\n",
    "alpha_list = np.array([0, 0.2, 0.5, 0.9, 1]) # alpha(hyperparameter)\n",
    "\n",
    "# means = np.array([[1,   0,  0,  0,  0.9,    0.4,    0.35,   0.35,   0.5],\n",
    "#                   [0,   1,  0,  0,  0.3,    0.9,    0.35,   0.3,    0.5],\n",
    "#                   [0,   0,  1,  0,  0.35,   0.35,   0.9,    0.3,    0.5],\n",
    "#                   [0,   0,  0,  1,  0.4,    0.3,    0.35,   0.9,    0.5]])\n",
    "\n",
    "# means = np.random.random((M, K))\n",
    "\n",
    "means = np.load('means.npy')\n",
    "print(means)\n",
    "\n",
    "M = means.shape[0] # 客户端数量\n",
    "K = means.shape[1] # 臂数量\n",
    "n_simu = 5 # 每个alpha的模拟次数\n",
    "\n",
    "print(f'M = {M}, K = {K}')\n",
    "\n",
    "def fp(p): # f(p) = 2^p * log(T)\n",
    "    return 2**p*np.log(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_WARM_START:\n",
    "    regret_reward = {}\n",
    "    raw_regret = {}\n",
    "    local_reward = {}\n",
    "    global_reward = {}\n",
    "    mixed_reward = {}\n",
    "else:\n",
    "    # try to load for a warm restart\n",
    "    try:\n",
    "        regret_reward = np.load('scores/regret_reward.npy',allow_pickle=True).item()\n",
    "    except FileNotFoundError:\n",
    "        regret_reward = {}\n",
    "\n",
    "    try:\n",
    "        raw_regret = np.load('scores/raw_regret.npy',allow_pickle=True).item()\n",
    "    except FileNotFoundError:\n",
    "        raw_regret = {}\n",
    "\n",
    "    try:\n",
    "        local_reward = np.load('scores/local_reward.npy',allow_pickle=True).item()\n",
    "    except FileNotFoundError:\n",
    "        local_reward = {}\n",
    "\n",
    "    try:\n",
    "        global_reward = np.load('scores/global_reward.npy',allow_pickle=True).item()\n",
    "    except FileNotFoundError:\n",
    "        global_reward = {}\n",
    "\n",
    "    try:\n",
    "        mixed_reward = np.load('scores/mixed_reward.npy',allow_pickle=True).item()\n",
    "    except FileNotFoundError:\n",
    "        mixed_reward = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for alpha in alpha_list:\n",
    "        try:\n",
    "            # the number of runs to run for this algo\n",
    "            nalgo = n_simu-len(raw_regret[str(round(alpha,2))])\n",
    "            if nalgo <= 0:\n",
    "                print(f'Using existing data for alpha: {alpha}')\n",
    "                continue\n",
    "        except KeyError:\n",
    "            # case of algo not loaded (ie 0 run already done)\n",
    "            raw_regret[str(round(alpha,2))] = []\n",
    "            local_reward[str(round(alpha,2))] = []\n",
    "            global_reward[str(round(alpha,2))] = []\n",
    "            mixed_reward[str(round(alpha,2))] = []\n",
    "            nalgo = n_simu\n",
    "\n",
    "        for i in tqdm.tqdm(range(nalgo), desc=\"Simulating {}\".format(\"P-Fed-UCB, alpha:\"+str(alpha))):\n",
    "            pfed = PFEDUCB(fp, T, means, alpha) # simulate a run with the chosen parameters\n",
    "            mixed_regret_1, local_reward_1, global_reward_1, mixed_reward_1 = pfed.simulate()\n",
    "            raw_regret[str(round(alpha,2))].append(mixed_regret_1)\n",
    "            local_reward[str(round(alpha,2))].append(local_reward_1)\n",
    "            global_reward[str(round(alpha,2))].append(global_reward_1)\n",
    "            mixed_reward[str(round(alpha,2))].append(mixed_reward_1)\n",
    "\n",
    "            regret_reward[str(round(alpha,2))] = [np.mean(raw_regret[str(round(alpha,2))], axis=0),\n",
    "                                                  np.std(raw_regret[str(round(alpha,2))], axis=0),\n",
    "                                                  np.min(raw_regret[str(round(alpha,2))], axis=0),\n",
    "                                                  np.max(raw_regret[str(round(alpha,2))], axis=0),\n",
    "                                                  np.mean(local_reward[str(round(alpha,2))], axis=0),\n",
    "                                                  np.mean(global_reward[str(round(alpha,2))], axis=0),\n",
    "                                                  np.mean(mixed_reward[str(round(alpha,2))], axis=0)]\n",
    "\n",
    "            del mixed_regret_1, local_reward_1, global_reward_1, mixed_reward_1\n",
    "\n",
    "    # also saves the scores if we ran the whole algorithm without interrupting\n",
    "    np.save('scores/raw_regret.npy', raw_regret)\n",
    "    np.save('scores/local_reward.npy',local_reward)\n",
    "    np.save('scores/global_reward.npy',global_reward)\n",
    "    np.save('scores/mixed_reward.npy',mixed_reward)\n",
    "    np.save('scores/regret_reward.npy', regret_reward)\n",
    "    del raw_regret, local_reward, global_reward, mixed_reward, regret_reward\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # save in case of interruption\n",
    "    print('alpha:', alpha, 'Number of tries ran: ', len(raw_regret[str(round(alpha,2))]))\n",
    "    np.save('scores/raw_regret.npy', raw_regret)\n",
    "    np.save('scores/local_reward.npy',local_reward)\n",
    "    np.save('scores/global_reward.npy',global_reward)\n",
    "    np.save('scores/mixed_reward.npy',mixed_reward)\n",
    "    np.save('scores/regret_reward.npy', regret_reward)\n",
    "    del raw_regret, local_reward, global_reward, regret_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    regret_reward = np.load('scores/regret_reward.npy',allow_pickle=True).item()\n",
    "except FileNotFoundError:\n",
    "    regret_reward = {}\n",
    "\n",
    "horizon_plot = -1\n",
    "fig = plt.figure(1,figsize=(9,6))\n",
    "for alpha in alpha_list:\n",
    "    plt.plot(regret_reward[str(round(alpha,2))][0][:horizon_plot], label=str(alpha))\n",
    "plt.xlabel('$t$', fontsize=20)\n",
    "plt.ylabel('Regret', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
